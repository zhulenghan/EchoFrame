{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa00ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import laion_clap\n",
    "# from extraction.vgg_sound import *\n",
    "# 在aws notebook环境需要加上这个\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, \"..\")))\n",
    "\n",
    "from audioldm import image_to_audio, build_model, clap_to_audio\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import soundfile as sf \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91852b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class V2AMapperMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    将(64,512)的clip特征先池化到(1,512),\n",
    "    再映射到(1,512).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=512, hidden_dim=1024, output_dim=512):\n",
    "        super().__init__()\n",
    "        # 可以先做一个简单的线性层, 或者堆叠多层\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, input_dim))  \n",
    "        # pooling后, shape变成 (1, input_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 64, 512)\n",
    "        # 先把 shape (B,64,512) pooling 到 (B,1,512)\n",
    "        # 这里可以用简单的mean替代，也可以用AdaptiveAvgPool2d\n",
    "        pooled = x.mean(dim=1)  # (B,512)\n",
    "\n",
    "        # 送入多层感知机映射到(512)\n",
    "        out = self.mlp(pooled)  # (B,512)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd1881da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"ckpts/best_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e344d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = V2AMapperMLP()\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=\"cpu\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf68a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load AudioLDM: %s audioldm-s-full-v2\n",
      "DiffusionWrapper has 185.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"audioldm-s-full-v2\"\n",
    "audioldm=build_model(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ece5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LargeVideoTestDataset(Dataset):\n",
    "    def __init__(self, data_dir, subset_ratio = 0.2, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: 保存所有 .pth 文件的目录，每个文件对应一个 sample。\n",
    "        transform: 如果需要对数据做预处理，可在这里传入。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 仅收集当前目录下所有的 pth 文件列表\n",
    "        file_list = []\n",
    "\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pth\"):\n",
    "                    file_list.append(os.path.join(root, file))\n",
    "\n",
    "        # 仅使用前 20% 的数据\n",
    "        num_samples = int(len(file_list) * subset_ratio)\n",
    "\n",
    "        self.file_paths = sorted(file_list)[:num_samples]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 在这里按需读取，而不是一次性加载全部\n",
    "        pth_path = self.file_paths[idx]\n",
    "        sample_data = torch.load(pth_path)  \n",
    "        clip_feat = sample_data['clip_features']  # (64, 512)\n",
    "        clap_feat = sample_data['clap_features']  # (1, 512)\n",
    "        id = sample_data['id']\n",
    "        caption = sample_data['caption']\n",
    "\n",
    "        if self.transform:\n",
    "            clip_feat, clap_feat = self.transform((clip_feat, clap_feat))\n",
    "\n",
    "        return clip_feat, clap_feat, id, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aedec30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/new_volume2/vgg_sound_emb\"\n",
    "partition = \"train\"\n",
    "data_dir = f\"{root}/{partition}\"\n",
    "vgg_sound = LargeVideoTestDataset(data_dir, subset_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "460b9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "total_len = len(vgg_sound)\n",
    "val_len = int(total_len * val_ratio)\n",
    "test_len = int(total_len * test_ratio)\n",
    "train_len = total_len - val_len - test_len\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    vgg_sound, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(42), \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1df6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feeb5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image2audio(file_name, images, duration=10, guidance_scale=2.5, random_seed=42, n_candidates=3):\n",
    "    waveform = clap_to_audio(\n",
    "        latent_diffusion=audioldm,\n",
    "        clap_feat=images,\n",
    "        seed=random_seed,\n",
    "        duration=duration,\n",
    "        guidance_scale=guidance_scale,\n",
    "        n_candidate_gen_per_text=int(n_candidates),\n",
    "    )  # [bs, 1, samples]\n",
    "\n",
    "    for i, wave in enumerate(waveform):\n",
    "        # filename = f\"{file_name}.wav\"\n",
    "        filename = file_name\n",
    "        sf.write(filename, wave[0], 16000, 'PCM_16') \n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1082826",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/mnt/new_volume/vgg_sound/scratch/shared/beegfs/hchen/train_data/VGGSound_final/video/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e24d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1826 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 512]) torch.Size([1, 1, 512]) ['-1_f4o5Lqkg_000059.mp4'] ['mosquito buzzing']\n",
      "batch shape:  [tensor([[ 2.1828e+01,  1.6783e+01,  3.1715e+00,  2.5373e+01,  2.6099e+01,\n",
      "          2.4544e+01,  1.3202e+01, -1.1837e+00,  2.7100e+00,  3.3163e-01,\n",
      "          5.0234e+00, -6.6225e+00,  9.7894e+00,  1.6295e+01,  9.4244e+00,\n",
      "         -6.2355e+00,  2.0865e+00,  5.0002e-01,  3.2720e+01, -8.4438e+00,\n",
      "          4.0931e+00,  1.8186e+01, -1.1150e+01,  1.0340e+00, -3.7985e+00,\n",
      "         -2.4221e+01, -4.8938e+01,  2.1103e+00, -1.0755e+01,  3.7562e+01,\n",
      "          7.1613e+00, -5.1924e+00, -2.9974e+01, -4.7938e+01, -3.8673e+01,\n",
      "         -7.1633e+00, -1.6234e+00, -1.2147e+01,  2.5153e+01, -8.7885e+00,\n",
      "          1.3659e+01, -3.0875e+01,  1.6361e+01,  1.8019e+01, -1.4823e+01,\n",
      "          3.2537e+00, -1.3500e+01, -8.7543e+00, -1.7502e+01, -4.0366e+00,\n",
      "          5.3313e+00, -2.2422e+01,  8.8823e+00,  2.6822e+00,  2.3186e+01,\n",
      "         -3.3767e+01, -7.4192e+00,  1.8020e+01, -2.3133e+01,  1.1055e+01,\n",
      "          1.1276e+01,  1.7679e+01,  1.2539e+01,  4.2380e+01, -3.5855e+00,\n",
      "          4.9935e-01, -2.4576e+00,  1.1448e+01,  2.2920e+00,  7.4773e+00,\n",
      "          7.1036e+00,  1.5895e+01, -1.2948e+01,  5.0304e-01,  3.7116e+01,\n",
      "         -7.5346e+00, -2.3544e+01,  1.8825e+00,  7.2965e-02,  1.1862e+01,\n",
      "         -3.2396e+00, -5.6385e+00,  7.1997e+00,  3.0217e+01, -2.4777e+01,\n",
      "          5.0573e+01, -1.4391e+01, -2.2428e+01, -1.5129e+01, -3.2876e+00,\n",
      "          1.1203e+00, -7.0294e+00, -1.2025e+01, -9.5465e+00,  1.5402e+00,\n",
      "          1.3573e+01, -8.3775e+00, -3.1471e+00,  1.6280e+01,  5.6568e+00,\n",
      "          1.2353e+01,  1.2141e+01, -2.0715e+01, -1.5437e+00,  1.7100e+01,\n",
      "          4.6914e-01,  2.9191e+01, -9.1174e+00,  3.9358e+00,  1.3539e+00,\n",
      "          8.1284e-01,  1.1657e+01, -2.4267e+01, -2.1213e+01,  2.7550e+01,\n",
      "          1.2047e+01,  2.5877e+00,  2.4142e+01, -2.3159e+01, -1.2488e+01,\n",
      "         -2.5663e+00,  8.0012e+00, -1.3821e+01,  3.0445e+01,  1.5587e+01,\n",
      "         -9.3007e-01,  1.5558e+01,  9.6855e+00, -2.8774e+00, -1.8278e+01,\n",
      "          1.4024e+01, -3.5741e+00,  1.3292e+01, -1.6727e+01,  1.2210e+01,\n",
      "         -8.0858e+00,  5.8247e+00, -2.4094e+01,  1.0547e+01,  1.2794e+01,\n",
      "         -2.5971e+01,  3.0930e+01, -1.3141e+01,  1.1802e+01,  3.5963e+01,\n",
      "         -5.9335e+00, -6.2522e-01, -7.8062e+00,  1.0255e+01, -3.3948e+01,\n",
      "          7.0047e+00,  2.0575e+01, -3.6329e+00, -2.4686e+01, -1.0974e+01,\n",
      "          1.8857e+01,  1.3537e+01, -4.1078e+00,  1.4539e+01, -3.4230e+00,\n",
      "         -8.2495e+00, -8.0417e+00, -3.5296e+01,  3.8206e+00,  2.5717e+01,\n",
      "          7.1258e+00,  2.2579e+01, -3.5251e+00,  2.2378e+01,  5.2441e+00,\n",
      "          1.7175e+01,  7.9242e+00,  4.2060e-01,  1.6458e+01,  4.8561e-01,\n",
      "         -8.7368e+00,  5.2391e+00, -1.2323e+01, -9.1436e+00, -1.2684e+01,\n",
      "          2.4133e+00,  2.0946e+00,  6.6713e+00,  2.9711e+01, -1.9345e+01,\n",
      "          1.2076e+00, -1.9880e-01, -1.7801e+00, -1.5882e+01,  2.5598e+01,\n",
      "         -3.4366e+01, -4.9491e+01,  2.3454e+01,  1.0917e+01,  6.1575e+00,\n",
      "          2.2712e+01, -8.6997e-01, -7.8909e+00, -4.0539e+00,  6.1323e+00,\n",
      "         -1.6329e+01, -1.8619e+00, -2.1580e+01, -2.9846e+01, -1.3830e+01,\n",
      "          2.5139e+01, -4.5495e+00,  1.6123e+01,  1.8176e+01,  2.9227e+00,\n",
      "          1.1889e+01, -2.8524e+01,  9.2287e-01, -9.4438e+00,  1.8528e+01,\n",
      "         -2.9227e+01, -1.7554e+01, -1.4507e-01,  2.3631e+01,  2.0912e+00,\n",
      "         -1.0586e+01,  9.8218e+00, -2.1563e+01, -2.8114e+01,  3.2922e+00,\n",
      "          1.6333e+01,  1.8856e+01, -1.2338e+00,  4.2341e+00,  2.4905e+01,\n",
      "          8.0343e+00,  4.8783e+00, -4.3034e+00, -1.0891e+01, -4.1382e+00,\n",
      "         -1.3722e+01,  5.9534e+00, -1.4517e+01,  1.1649e+01, -1.7801e+01,\n",
      "          2.9486e+01,  1.5219e+01, -8.9062e-01, -9.5029e+00,  1.4905e+01,\n",
      "          2.7067e+00,  2.7340e+01,  1.8496e+01, -1.1600e+01,  2.8138e+00,\n",
      "          1.6289e+01,  3.6122e+00,  2.4152e+01,  1.5965e+01,  3.9783e+00,\n",
      "          5.0256e+00, -2.0560e+01,  6.2547e+00, -3.9939e-03,  7.3737e+00,\n",
      "         -2.2150e+01,  7.3096e+00,  3.2750e+01,  8.1017e+00,  3.7476e+00,\n",
      "         -1.5748e+01,  5.4877e+00,  4.9740e-01,  1.1495e+01, -1.7667e+01,\n",
      "          1.7235e+01,  1.5918e+01, -1.9040e+01,  8.8921e+00, -1.8318e+01,\n",
      "         -4.7344e+00, -6.8093e+00, -1.8465e+01,  1.5924e+01, -1.4353e+01,\n",
      "         -1.1051e+01, -3.4517e+01,  7.8255e+00, -6.0993e+00, -2.1203e-01,\n",
      "          5.7411e+00, -8.7186e+00,  2.0310e+01,  2.8528e+01, -7.4943e+00,\n",
      "          1.0932e+01,  3.8253e+00,  6.8268e-01,  2.4491e+00,  2.9784e+01,\n",
      "         -2.1559e+01, -1.6676e+01, -8.3467e+00, -1.6455e+01, -5.9442e+00,\n",
      "          4.4545e+01, -1.3604e+01, -1.5211e+01,  2.5174e+01, -2.6946e+01,\n",
      "          4.0566e+00,  4.9718e+00,  4.8490e+01, -1.5858e+01,  7.0346e+00,\n",
      "          1.9477e+01,  1.9205e+01, -1.7304e+01,  1.0489e+01, -9.6732e+00,\n",
      "          1.8077e+01, -1.0625e+01,  7.2849e+00, -1.9122e+01,  1.0758e+01,\n",
      "         -9.7813e+00,  6.3792e+00, -2.0139e+01, -1.0564e+00,  4.0812e+00,\n",
      "         -4.3127e+00,  4.3548e+00, -2.0897e+01, -1.4974e+01, -1.3558e+01,\n",
      "         -1.7764e+01, -1.0774e+01,  3.7718e+01,  4.5142e+00, -1.2729e+01,\n",
      "          1.2764e+01,  3.5022e+00, -8.2721e+00, -2.9884e+01,  3.1895e+01,\n",
      "         -1.7761e+00,  3.2490e+01, -1.5258e+01, -1.6121e+00,  2.9311e+00,\n",
      "         -8.4245e+00,  2.3120e+01, -3.0876e+00, -7.2336e+00, -8.7601e-02,\n",
      "         -1.3833e+00,  1.4931e+01,  1.1223e+01, -2.4568e+00,  2.8702e+01,\n",
      "         -2.0844e-01, -1.3707e+00,  2.4411e+01, -1.4016e+00,  2.0754e+01,\n",
      "         -1.9375e+01,  1.2693e+01, -1.1967e+01,  2.9464e+01, -3.3409e+00,\n",
      "          2.6697e+01, -8.2660e+00,  2.7999e+00,  1.5911e+00,  3.7180e+00,\n",
      "          3.3942e+01,  3.9076e+01, -1.2110e+01, -1.8506e+00, -3.0481e+01,\n",
      "          5.8162e+00,  1.0677e+01,  1.3157e+01,  1.7438e+01, -2.5783e+01,\n",
      "          2.1712e+01,  6.7860e+00, -2.5164e+01, -1.0545e+01, -1.7941e+01,\n",
      "          1.0698e+01,  3.4532e+01, -2.6600e+01, -1.1960e+01, -8.7190e+00,\n",
      "          3.9402e+00,  6.3957e+00,  2.2461e+01,  3.4638e+01, -1.9844e+01,\n",
      "          2.7024e+01,  1.1273e+00, -5.9590e+00,  2.1737e+01, -1.4387e+01,\n",
      "         -6.4944e+00, -2.9910e+00, -1.8612e+01,  7.1362e+00, -3.3293e+01,\n",
      "          2.4853e+01, -9.5916e+00,  2.4179e+01, -2.1183e+01,  1.2571e+01,\n",
      "          4.1843e+01, -1.1372e+01, -1.6854e+01, -4.0665e+00, -1.0868e+01,\n",
      "         -1.0825e+01,  1.1586e+01, -2.1749e+00, -3.8887e+01, -4.0772e+01,\n",
      "         -3.6381e+00, -1.4881e+01, -1.3487e+01, -2.4549e+00,  1.3511e+01,\n",
      "          2.6283e+01, -1.8623e+01,  2.8223e+01,  2.5730e+00,  1.0416e+01,\n",
      "         -1.2952e+01, -1.2216e+01,  1.2253e+01,  9.7465e+00, -8.0879e+00,\n",
      "          3.8970e+01, -2.9440e+00,  9.6032e+00, -2.8414e+01, -7.0459e+00,\n",
      "          1.1631e+01,  1.1133e+01,  1.6503e+01, -4.0935e+00,  8.2833e+00,\n",
      "         -1.5259e+01,  9.9353e+00,  4.7276e+00,  9.5946e+00, -8.3197e+00,\n",
      "         -1.8994e+01, -1.7129e+01, -3.1819e+01,  1.8395e+00, -6.1924e+00,\n",
      "          4.0615e+01, -2.7236e+00,  3.6938e+01,  2.0779e+01, -3.5260e+01,\n",
      "          1.0664e+01, -4.6269e+01, -1.7445e+01,  2.0452e+01, -3.3230e+00,\n",
      "         -1.4230e+00, -5.9600e-01, -3.4260e+01,  1.0914e+01,  3.0191e+00,\n",
      "         -5.8950e+00,  1.0221e+01, -1.4891e+01,  2.6244e+01,  2.4242e+00,\n",
      "          1.0930e-01, -2.3577e+01,  1.6190e+01, -6.7352e+00,  2.4650e+01,\n",
      "          3.7459e+00,  1.5839e+01, -1.0822e+01, -5.2380e+00,  3.8811e+01,\n",
      "         -8.9566e+00,  2.9553e+01,  1.6627e+00,  6.0208e+00,  2.7272e+01,\n",
      "          1.0788e+01, -2.4004e+01,  5.8227e+00,  9.5296e+00, -1.7868e+01,\n",
      "         -9.4499e-01, -3.8888e+01,  1.3077e+01, -1.0331e+01,  2.8419e+00,\n",
      "         -5.0849e+00,  3.0298e+01, -4.5092e+00, -8.6356e+00,  9.0643e+00,\n",
      "         -1.4120e+01, -2.9725e+00,  1.0121e+00, -8.4253e-01, -4.9127e+00,\n",
      "         -9.2130e+00, -2.5840e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)]\n",
      "batch type:  <class 'list'>\n",
      "key: fbank\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 1024, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cnt = 0\n",
    "for clip_feat, clap_feat, id, caption in tqdm(test_loader):\n",
    "    # clip_feat: (1, 64, 512)\n",
    "    # clap_feat: (1, 512)\n",
    "    # id: (1,)\n",
    "    # caption: (1,)\n",
    "    print(clip_feat.shape, clap_feat.shape, id, caption)\n",
    "    clip_feat = clip_feat.to(device)  # (64, 512)\n",
    "    # clap_feat = clap_feat.squeeze(0).to(devcice)  # (512)\n",
    "\n",
    "    gen_clap_feat = model(clip_feat).to(device=device)  # (1, 512)\n",
    "    \n",
    "    image2audio(\n",
    "        file_name=\"/home/ubuntu/project/v2a-mapper/train/test_inf/test_vgg/test_outputs/\" + id[0][:-4] + \"gen.wav\",\n",
    "        images=gen_clap_feat.to(device=device),\n",
    "        duration=10,\n",
    "        guidance_scale=2.5,\n",
    "        random_seed=42,\n",
    "        n_candidates=3\n",
    "    )\n",
    "    !ffmpeg -i {video_path + id[0]} -vn -acodec pcm_s16le -ar 44100 -ac 2 /home/ubuntu/project/v2a-mapper/train/test_inf/test_vgg/test_outputs/{id[0][:-4]}.wav\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eacc9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "045b75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_feat, clap_feat, id, caption = next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "653ef0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 512]) torch.Size([1, 1, 512]) ['-1_f4o5Lqkg_000059.mp4'] ['mosquito buzzing']\n"
     ]
    }
   ],
   "source": [
    "print(clip_feat.shape, clap_feat.shape, id, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00e3ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 11.2.0 (Anaconda gcc)\n",
      "  configuration: --prefix=/home/ubuntu/miniconda3/envs/v2a-mapper --cc=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-cc --ar=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ar --nm=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-nm --ranlib=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ranlib --strip=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-strip --disable-doc --enable-swresample --enable-swscale --enable-openssl --enable-libxml2 --enable-libtheora --enable-demuxer=dash --enable-postproc --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libdav1d --enable-zlib --enable-libaom --enable-pic --enable-shared --disable-static --disable-gpl --enable-version3 --disable-sdl2 --enable-libopenh264 --enable-libopus --enable-libmp3lame --enable-libopenjpeg --enable-libvorbis --enable-pthreads --enable-libtesseract --enable-libvpx\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/mnt/new_volume/vgg_sound/scratch/shared/beegfs/hchen/train_data/VGGSound_final/video/-1_f4o5Lqkg_000059.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "  Duration: 00:00:10.01, start: 0.000000, bitrate: 1506 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1280x720, 1102 kb/s, 29.97 fps, 29.97 tbr, 60k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 151 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : IsoMedia File Produced by Google, 5-11-2011\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/home/ubuntu/project/v2a-mapper/train/test_inf/test_vgg/test_outputs/-1_f4o5Lqkg_000059.mp4.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : IsoMedia File Produced by Google, 5-11-2011\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 pcm_s16le\n",
      "\u001b[1;35m[out#0/wav @ 0x108fba40] \u001b[0mvideo:0kB audio:1724kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004417%\n",
      "size=    1724kB time=00:00:09.98 bitrate=1414.5kbits/s speed= 254x    \n"
     ]
    }
   ],
   "source": [
    "# ! cp {video_path + id[0]} /home/ubuntu/project/v2a-mapper/train/test_inf/test_vgg/test_video\n",
    "\n",
    "!ffmpeg -i {video_path + id[0]} -vn -acodec pcm_s16le -ar 44100 -ac 2 /home/ubuntu/project/v2a-mapper/train/test_inf/test_vgg/test_outputs/{id[0]}.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2db478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0353102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17399cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_feat shape: torch.Size([1, 64, 512])\n",
      "clap_feat shape: torch.Size([1, 1, 512])\n",
      "id: ['-1_f4o5Lqkg_000059.mp4']\n",
      "caption: ['mosquito buzzing']\n"
     ]
    }
   ],
   "source": [
    "print(f\"clip_feat shape: {clip_feat.shape}\")\n",
    "print(f\"clap_feat shape: {clap_feat.shape}\")\n",
    "print(f\"id: {id}\")\n",
    "print(f\"caption: {caption}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f78d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c57b8fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x64 and 512x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gen_clap_feat = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_feat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mV2AMapperMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     28\u001b[39m pooled = x.mean(dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B,512)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 送入多层感知机映射到(512)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B,512)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1x64 and 512x1024)"
     ]
    }
   ],
   "source": [
    "gen_clap_feat = model(clip_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6376cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load AudioLDM: %s audioldm-s-full-v2\n",
      "DiffusionWrapper has 185.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = \"audioldm-s-full-v2\"\n",
    "audioldm=build_model(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c12ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image2audio(file_name, images, duration=10, guidance_scale=2.5, random_seed=42, n_candidates=3):\n",
    "    waveform = clap_to_audio(\n",
    "        latent_diffusion=audioldm,\n",
    "        clap_feat=images,\n",
    "        seed=random_seed,\n",
    "        duration=duration,\n",
    "        guidance_scale=guidance_scale,\n",
    "        n_candidate_gen_per_text=int(n_candidates),\n",
    "    )  # [bs, 1, samples]\n",
    "\n",
    "    for i, wave in enumerate(waveform):\n",
    "        filename = f\"{file_name}.wav\"\n",
    "        sf.write(filename, wave[0], 16000, 'PCM_16') \n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c035cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape:  [tensor([[  8.4076,   8.9150,   8.1998,  20.5605,  15.6725,  16.5475,   5.3757,\n",
      "          -3.4283,  -0.2870,   3.5352,  -0.9050, -10.0235,   7.3880,   9.9746,\n",
      "           7.2894,  -5.4092,   2.0637,   0.5552,  20.3179,  -1.8790,   5.2214,\n",
      "           8.8170, -10.7283,   2.8796,  -4.3717, -20.2293, -34.6853,   0.9166,\n",
      "          -8.3378,  28.2999,   5.3379,  -3.9145, -16.4478, -31.0907, -21.6145,\n",
      "          -2.3070,  -3.5866, -10.9111,  15.1106,  -7.7051,   8.4162, -21.8627,\n",
      "           7.8714,  11.9345, -11.4393,   3.4052,  -5.2862,  -5.9282, -10.0566,\n",
      "          -6.0752,   1.0733, -12.8453,   2.8973,  -1.8153,  13.1791, -19.0822,\n",
      "          -6.3574,   6.2898, -11.7146,   8.4148,   7.1210,   9.3209,  10.1412,\n",
      "          27.7904,  -1.6135,   4.5770,  -2.2091,   5.5536,   2.7890,   4.5220,\n",
      "           5.8580,  11.6451,  -3.7875,  -5.1803,  25.6695, -10.0351, -19.0158,\n",
      "          -3.7769,  -0.2103,  10.7586,  -3.6818,  -2.6625,   4.5504,  25.3820,\n",
      "         -12.0752,  38.3779, -13.6586, -10.7105,  -3.8877,   1.6304,   7.0527,\n",
      "          -2.9231,  -9.8770,  -5.5127,   3.2123,   7.8394,  -0.6313,  -4.9320,\n",
      "           9.8694,   4.4119,   6.3909,  10.0969, -19.1974,  -1.3364,  11.6657,\n",
      "          -1.9162,  14.7971,  -8.3985,  -1.0129,   1.6698,   2.4880,   8.3777,\n",
      "         -16.6411, -13.8714,  19.0326,   9.4777,   1.3214,  14.0978, -19.1782,\n",
      "          -5.4691,  -1.8720,   8.6862,  -7.9490,  18.3305,   6.1264,   1.0372,\n",
      "           8.1906,   8.3666,  -4.7482,  -9.0663,   9.1480,   2.7818,   3.6412,\n",
      "         -10.2840,  11.4727,  -3.0095,   5.0164, -15.2814,   4.5882,   5.5792,\n",
      "         -16.6938,  19.0957,  -5.2509,   2.5815,  24.3331,  -8.7262,  -1.5981,\n",
      "          -7.0782,   5.3812, -26.5674,   3.7921,  13.1837,  -2.5800, -17.7443,\n",
      "          -0.3748,  14.2858,   8.3274,  -4.3272,   3.6124,  -5.7737, -12.4779,\n",
      "          -3.3568, -21.1752,  -3.7462,  17.1556,   6.4189,  10.1594,  -0.5709,\n",
      "          10.4112,   3.4329,  12.1247,   4.4357,  -4.7269,  12.7038,   0.4101,\n",
      "          -4.9785,   1.6459,  -5.1719,  -2.6479,  -5.1560,  -0.8710,   3.9568,\n",
      "          -0.1819,  21.3682, -12.2603,  -1.0287,  -1.3889,   2.5169,  -8.9491,\n",
      "          19.6463, -19.9310, -27.5700,  11.7184,   2.7856,   4.0961,  14.6405,\n",
      "          -2.5442,  -0.8545,  -1.1058,   1.0279,  -6.3350,   0.3374, -16.8269,\n",
      "         -15.0550, -12.4758,  15.0938, -10.6137,   7.4821,  10.3591,   5.1522,\n",
      "           5.5188, -16.1277,  -0.9620,  -7.8083,  11.3751, -15.8670,  -8.9459,\n",
      "          -3.3650,  11.4435,   1.6561, -11.1254,   6.5430, -10.8454, -20.0392,\n",
      "          -0.4360,   9.7971,  13.4680,   1.5877,   5.5812,  15.1370,   0.7864,\n",
      "           1.9011,  -0.8348,  -8.3580,  -5.3884, -11.4882,   4.6880,  -9.3212,\n",
      "           4.9082,  -8.3704,  19.9802,  11.2891,   3.2877,  -8.9454,  13.4240,\n",
      "           2.0809,  16.0730,   9.9984,  -4.8342,   2.1401,  10.5608,   6.4621,\n",
      "          15.3011,  11.1102,   5.1484,   5.0224, -12.2820,   4.5802,  -0.4687,\n",
      "           5.2509, -15.6868,   5.3784,  22.1157,   9.1133,   6.5982, -13.3450,\n",
      "           1.4247,  -2.3346,   4.6727, -14.2202,  14.4035,  13.3068, -13.3888,\n",
      "           1.8323,  -6.9593,  -2.2555,  -2.5306, -14.9091,  10.6991,  -9.3013,\n",
      "          -8.4170, -22.1327,   4.1257,   2.3276,   0.9745,   4.4839,  -1.2273,\n",
      "          12.6879,  15.1010,  -4.4681,   8.3958,   0.6381,  -0.2118,  -2.5805,\n",
      "          24.1499, -14.1687,  -7.2106,  -4.7708,  -9.8662,  -6.5331,  28.7974,\n",
      "         -11.1411, -11.5291,  13.0147, -22.9073,   2.2576,   4.6882,  37.7873,\n",
      "         -13.4290,   3.5967,  14.7228,  17.0023, -12.7209,   3.0568,  -5.8372,\n",
      "          10.2968,  -8.6951,   4.1206, -10.9533,   1.1928,  -3.9631,   9.8025,\n",
      "          -6.8657,  -0.1055,   3.9982,  -5.1924,   2.5462, -12.6998, -13.3809,\n",
      "          -4.9328, -11.2078,  -7.1939,  27.5474,  -0.5468,  -5.1820,   5.1865,\n",
      "           2.7510,  -8.5192, -20.1030,  21.7440,  -1.8142,  22.2714, -10.9925,\n",
      "          -0.2920,   6.8827,  -4.6690,  15.9015,  -3.3222,  -6.4105,  -2.8723,\n",
      "           1.4311,  12.7553,  13.9421,   3.4983,  24.8737,  -3.4509,   0.4227,\n",
      "          20.1217,  -2.6963,  16.1773, -11.2972,  10.3376,  -4.6006,  20.0169,\n",
      "          -0.0973,  17.9308,  -1.8114,  -4.7451,  -5.0972,   5.7719,  18.3982,\n",
      "          24.4594,  -7.5656,  -8.5140, -23.6520,   7.7347,   7.0600,   9.0056,\n",
      "          10.3440, -13.9001,  14.0203,   2.7887, -12.4896,  -7.9114,  -6.0569,\n",
      "           7.6632,  26.6287, -12.6629,  -5.2258,  -4.8431,   4.5695,   5.0974,\n",
      "          15.3112,  24.4001, -16.1214,  19.6741,  -0.3401,  -0.0612,  16.0176,\n",
      "          -8.7106,  -2.3980,  -4.4537, -10.1675,   2.2917, -20.2524,  16.8537,\n",
      "          -6.3338,  13.7723, -17.0099,  10.6238,  26.3222,  -8.4581,  -7.0652,\n",
      "          -1.0764,  -9.5218, -11.8694,   7.1971,   1.9404, -24.6730, -24.1640,\n",
      "          -1.3750, -10.2812, -10.2492,  -1.4904,   5.2049,  19.1003, -18.5899,\n",
      "          18.0271,   4.6742,   6.9390,  -6.3431,  -8.0349,   1.8571,   5.4075,\n",
      "          -2.2939,  24.3889,   6.0596,   3.5674, -15.1293,  -4.1581,   4.7323,\n",
      "          10.9344,   8.6953,  -2.8208,   1.6947,  -6.9321,   8.3513,   1.1471,\n",
      "           3.9681,  -0.9484, -12.9995, -14.1099, -19.5946,   3.6620,  -1.2506,\n",
      "          27.0541,  -1.5228,  26.1992,  13.6533, -20.5154,   6.4521, -29.6755,\n",
      "         -17.5326,  10.4520,   2.0324,  -2.4682,   1.5242, -24.5079,   6.4076,\n",
      "           5.1180,  -8.9066,   3.2999, -11.6018,  15.1982,   0.3393,   2.1026,\n",
      "         -16.8013,  11.0106,  -4.3022,  13.2372,   3.0258,  14.0879,  -6.5926,\n",
      "          -2.3217,  27.2976,  -7.1535,  15.0697,   7.9293,   1.7094,  21.0942,\n",
      "          11.0986, -19.9912,   0.9520,   2.8403, -11.8288,   1.4820, -24.1781,\n",
      "           8.0877,  -2.1914,   0.9445,  -1.3415,  20.2479,   2.2468,  -6.3403,\n",
      "          12.6112,  -7.0936,  -0.9836,   5.8754,   1.1273,  -3.0962, -12.1732,\n",
      "          -0.7125]], device='cuda:0', grad_fn=<ToCopyBackward0>)]\n",
      "batch type:  <class 'list'>\n",
      "key: fbank\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 1024, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 200/200 [00:17<00:00, 11.56it/s]\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:580: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 6.1683670e-05,  2.8324412e-04,  8.3505845e-05, ...,\n",
       "         -4.0632939e-01, -3.9695010e-01, -4.3544635e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image2audio(\n",
    "    file_name=\"test3\",\n",
    "    images=gen_clap_feat.to(device=devcice),\n",
    "    duration=10,\n",
    "    guidance_scale=2.5,\n",
    "    random_seed=42,\n",
    "    n_candidates=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff764e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2a-mapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
