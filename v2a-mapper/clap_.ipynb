{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import laion_clap\n",
    "from extraction.vgg_sound import *\n",
    "from audioldm import image_to_audio, build_model, clap_to_audio\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import soundfile as sf \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loading HTSAT-tiny model config.\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Loading pretrained HTSAT-tiny-roberta weights (/home/ubuntu/project/v2a-mapper/pretrain/clap_htsat_tiny.pt).\n"
     ]
    }
   ],
   "source": [
    "from audioldm.clap.encoders import CLAPAudioEmbeddingClassifierFreev2\n",
    "CLAP = CLAPAudioEmbeddingClassifierFreev2(\n",
    "    key='waveform',\n",
    "    pretrained_path=\"/home/ubuntu/project/v2a-mapper/pretrain/clap_htsat_tiny.pt\",\n",
    "    sampling_rate=16000,\n",
    "    embed_mode=\"audio\",\n",
    "    amodel=\"HTSAT-tiny\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = \"/mnt/new_volume2/vgg_sound_emb\"\n",
    "partition = \"train\"\n",
    "data_dir = f\"{root}/{partition}\"\n",
    "\n",
    "class LargeVideoDataset(Dataset):\n",
    "    def __init__(self, data_dir, subset_ratio = 0.2, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: 保存所有 .pth 文件的目录，每个文件对应一个 sample。\n",
    "        transform: 如果需要对数据做预处理，可在这里传入。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 仅收集当前目录下所有的 pth 文件列表\n",
    "        file_list = []\n",
    "\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pth\"):\n",
    "                    file_list.append(os.path.join(root, file))\n",
    "\n",
    "        # 仅使用前 20% 的数据\n",
    "        num_samples = int(len(file_list) * subset_ratio)\n",
    "\n",
    "        self.file_paths = sorted(file_list)[:num_samples]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 在这里按需读取，而不是一次性加载全部\n",
    "        pth_path = self.file_paths[idx]\n",
    "        sample_data = torch.load(pth_path)  \n",
    "        clip_feat = sample_data['clip_features']  # (64, 512)\n",
    "        clap_feat = sample_data['clap_features']  # (1, 512)\n",
    "\n",
    "        if self.transform:\n",
    "            clip_feat, clap_feat = self.transform((clip_feat, clap_feat))\n",
    "\n",
    "        return clip_feat, clap_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset = LargeVideoDataset(data_dir, subset_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg_dataset = VGGSound(root=\"/home/ubuntu/project/subdata/video\",\n",
    "#                            csv_path=\"/home/ubuntu/project/subdata/train_subset.csv\",\n",
    "#                            sample_rate =  16000)\n",
    "\n",
    "\n",
    "# data = vgg_dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1JWJSFMGrN4_000030.mp4',\n",
       " 'caption': 'male singing',\n",
       " 'audio': tensor([-0.0032,  0.0149,  0.0367,  ...,  0.0535,  0.0584,  0.0576]),\n",
       " 'clip_video': Image([[[[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]]],\n",
       " \n",
       " \n",
       "        [[[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]]],\n",
       " \n",
       " \n",
       "        [[[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]],\n",
       " \n",
       "         [[0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          ...,\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.4157, 0.4196, 0.4392,  ..., 0.2902, 0.3059, 0.3059],\n",
       "          [0.4118, 0.4235, 0.4392,  ..., 0.3098, 0.3020, 0.3176],\n",
       "          [0.4157, 0.4235, 0.4392,  ..., 0.3137, 0.2980, 0.3020],\n",
       "          ...,\n",
       "          [0.6667, 0.6784, 0.6745,  ..., 0.5647, 0.5882, 0.5922],\n",
       "          [0.6314, 0.6392, 0.6510,  ..., 0.6000, 0.6118, 0.6157],\n",
       "          [0.6392, 0.6471, 0.6627,  ..., 0.6235, 0.6353, 0.6471]],\n",
       " \n",
       "         [[0.7412, 0.7451, 0.7569,  ..., 0.4941, 0.5098, 0.5098],\n",
       "          [0.7373, 0.7490, 0.7529,  ..., 0.5137, 0.5059, 0.5216],\n",
       "          [0.7412, 0.7490, 0.7529,  ..., 0.5176, 0.5020, 0.5059],\n",
       "          ...,\n",
       "          [0.8627, 0.8745, 0.8706,  ..., 0.7882, 0.7922, 0.7961],\n",
       "          [0.8275, 0.8353, 0.8471,  ..., 0.8078, 0.8039, 0.8039],\n",
       "          [0.8353, 0.8431, 0.8588,  ..., 0.8314, 0.8314, 0.8314]],\n",
       " \n",
       "         [[0.8824, 0.8863, 0.9020,  ..., 0.7569, 0.7725, 0.7725],\n",
       "          [0.8784, 0.8902, 0.8980,  ..., 0.7765, 0.7686, 0.7843],\n",
       "          [0.8824, 0.8902, 0.8980,  ..., 0.7804, 0.7647, 0.7686],\n",
       "          ...,\n",
       "          [0.9608, 0.9725, 0.9686,  ..., 0.9451, 0.9569, 0.9608],\n",
       "          [0.9255, 0.9333, 0.9451,  ..., 0.9725, 0.9725, 0.9725],\n",
       "          [0.9333, 0.9412, 0.9569,  ..., 0.9961, 0.9961, 0.9961]]],\n",
       " \n",
       " \n",
       "        [[[0.4157, 0.4196, 0.4392,  ..., 0.2902, 0.3059, 0.3059],\n",
       "          [0.4118, 0.4235, 0.4392,  ..., 0.3098, 0.3020, 0.3176],\n",
       "          [0.4157, 0.4235, 0.4392,  ..., 0.3137, 0.2980, 0.3020],\n",
       "          ...,\n",
       "          [0.6667, 0.6784, 0.6784,  ..., 0.5647, 0.5882, 0.5922],\n",
       "          [0.6314, 0.6392, 0.6510,  ..., 0.6000, 0.6118, 0.6157],\n",
       "          [0.6392, 0.6471, 0.6627,  ..., 0.6235, 0.6353, 0.6471]],\n",
       " \n",
       "         [[0.7412, 0.7451, 0.7569,  ..., 0.4941, 0.5098, 0.5098],\n",
       "          [0.7373, 0.7490, 0.7529,  ..., 0.5137, 0.5059, 0.5216],\n",
       "          [0.7412, 0.7490, 0.7529,  ..., 0.5176, 0.5020, 0.5059],\n",
       "          ...,\n",
       "          [0.8627, 0.8745, 0.8745,  ..., 0.7882, 0.7922, 0.7961],\n",
       "          [0.8275, 0.8353, 0.8471,  ..., 0.8078, 0.8039, 0.8039],\n",
       "          [0.8353, 0.8431, 0.8588,  ..., 0.8314, 0.8314, 0.8314]],\n",
       " \n",
       "         [[0.8824, 0.8863, 0.9020,  ..., 0.7569, 0.7725, 0.7725],\n",
       "          [0.8784, 0.8902, 0.8980,  ..., 0.7765, 0.7686, 0.7843],\n",
       "          [0.8824, 0.8902, 0.8980,  ..., 0.7804, 0.7647, 0.7686],\n",
       "          ...,\n",
       "          [0.9608, 0.9725, 0.9765,  ..., 0.9451, 0.9569, 0.9608],\n",
       "          [0.9255, 0.9333, 0.9451,  ..., 0.9725, 0.9725, 0.9725],\n",
       "          [0.9333, 0.9412, 0.9569,  ..., 0.9961, 0.9961, 0.9961]]],\n",
       " \n",
       " \n",
       "        [[[0.4157, 0.4196, 0.4392,  ..., 0.2902, 0.3059, 0.3059],\n",
       "          [0.4118, 0.4235, 0.4392,  ..., 0.3098, 0.3020, 0.3176],\n",
       "          [0.4157, 0.4235, 0.4392,  ..., 0.3137, 0.2980, 0.3020],\n",
       "          ...,\n",
       "          [0.6667, 0.6784, 0.6784,  ..., 0.5647, 0.5882, 0.5922],\n",
       "          [0.6314, 0.6392, 0.6510,  ..., 0.6000, 0.6118, 0.6157],\n",
       "          [0.6392, 0.6471, 0.6627,  ..., 0.6235, 0.6353, 0.6471]],\n",
       " \n",
       "         [[0.7412, 0.7451, 0.7569,  ..., 0.4941, 0.5098, 0.5098],\n",
       "          [0.7373, 0.7490, 0.7529,  ..., 0.5137, 0.5059, 0.5216],\n",
       "          [0.7412, 0.7490, 0.7529,  ..., 0.5176, 0.5020, 0.5059],\n",
       "          ...,\n",
       "          [0.8627, 0.8745, 0.8745,  ..., 0.7882, 0.7922, 0.7961],\n",
       "          [0.8275, 0.8353, 0.8471,  ..., 0.8078, 0.8039, 0.8039],\n",
       "          [0.8353, 0.8431, 0.8588,  ..., 0.8314, 0.8314, 0.8314]],\n",
       " \n",
       "         [[0.8824, 0.8863, 0.9020,  ..., 0.7569, 0.7725, 0.7725],\n",
       "          [0.8784, 0.8902, 0.8980,  ..., 0.7765, 0.7686, 0.7843],\n",
       "          [0.8824, 0.8902, 0.8980,  ..., 0.7804, 0.7647, 0.7686],\n",
       "          ...,\n",
       "          [0.9608, 0.9725, 0.9765,  ..., 0.9451, 0.9569, 0.9608],\n",
       "          [0.9255, 0.9333, 0.9451,  ..., 0.9725, 0.9725, 0.9725],\n",
       "          [0.9333, 0.9412, 0.9569,  ..., 0.9961, 0.9961, 0.9961]]]], )}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_bs = data['audio'].unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:580: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# embed = CLAP.forward(data['audio'].unsqueeze(0).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load AudioLDM: %s audioldm-s-full-v2\n",
      "DiffusionWrapper has 185.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loading HTSAT-tiny model config.\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = \"audioldm-s-full-v2\"\n",
    "audioldm=build_model(model_name=MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image2audio(file_name, images, duration=10, guidance_scale=2.5, random_seed=42, n_candidates=3):\n",
    "    waveform = clap_to_audio(\n",
    "        latent_diffusion=audioldm,\n",
    "        clap_feat=images,\n",
    "        seed=random_seed,\n",
    "        duration=duration,\n",
    "        guidance_scale=guidance_scale,\n",
    "        n_candidate_gen_per_text=int(n_candidates),\n",
    "    )  # [bs, 1, samples]\n",
    "\n",
    "    for i, wave in enumerate(waveform):\n",
    "        filename = f\"../output/{file_name}.wav\"\n",
    "        sf.write(filename, wave[0], 16000, 'PCM_16') \n",
    "\n",
    "    return waveform\n",
    "\n",
    "image2audio(\n",
    "    file_name=\"test2\",\n",
    "    images=video_dataset[2][1].to('cuda:0'),\n",
    "    duration=10,\n",
    "    guidance_scale=2.5,\n",
    "    random_seed=42,\n",
    "    n_candidates=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape:  [tensor([[-1.8063e-02,  4.8113e-02,  3.5327e-02,  1.9750e-02, -1.2734e-02,\n",
      "         -2.0392e-02, -1.8764e-02,  2.5611e-02, -3.5815e-03, -9.2289e-03,\n",
      "          3.7888e-03, -7.9979e-02,  2.4839e-02,  9.6638e-02,  2.1745e-02,\n",
      "         -5.8274e-02, -9.0003e-03, -2.5673e-03,  5.9004e-02,  2.8808e-02,\n",
      "          4.1845e-02, -1.0983e-02, -4.7954e-02,  3.9691e-02, -9.9765e-03,\n",
      "         -1.9808e-02, -3.6131e-02, -1.7208e-02,  2.9788e-03,  2.3228e-02,\n",
      "          6.1867e-02,  3.1000e-02, -3.6792e-02, -2.0753e-02, -2.7919e-02,\n",
      "          3.3872e-02, -4.1604e-02, -4.5168e-02, -1.0017e-03, -5.2476e-02,\n",
      "          2.5796e-02,  9.3767e-03, -1.5496e-02,  6.9663e-02, -1.6264e-02,\n",
      "         -4.9651e-02,  2.8183e-02, -2.0987e-02,  1.3949e-02,  2.7978e-02,\n",
      "         -1.3387e-02, -6.5049e-02, -6.1874e-02,  5.2723e-03,  8.7065e-03,\n",
      "         -7.6076e-02,  3.0232e-02, -8.2282e-02, -3.7384e-02,  1.6844e-02,\n",
      "          2.7681e-02, -3.3685e-02,  2.1811e-02,  2.1942e-02, -7.0906e-04,\n",
      "          6.8498e-02,  2.7641e-02,  6.4668e-02,  2.8580e-03,  2.4845e-02,\n",
      "          8.1207e-02,  6.7942e-02, -3.6615e-02, -5.0179e-02,  2.2532e-02,\n",
      "         -2.3335e-02, -6.1587e-02,  2.1671e-02,  4.8852e-02,  3.2754e-02,\n",
      "         -5.9609e-02, -4.1044e-03, -5.4506e-03,  1.8671e-02,  5.0556e-02,\n",
      "          6.8499e-02, -3.8673e-02, -3.0504e-02, -7.5201e-02,  5.1899e-02,\n",
      "          6.8103e-02,  1.3825e-02, -1.2327e-01,  2.1822e-02,  2.4050e-02,\n",
      "         -6.8233e-02,  1.8330e-02,  2.0809e-02,  2.2516e-04,  4.5943e-03,\n",
      "         -2.7160e-02,  6.7854e-02,  6.1417e-02, -2.5775e-02,  4.4581e-03,\n",
      "          8.4233e-02,  3.0256e-02,  1.8297e-02, -3.5375e-02, -2.5347e-03,\n",
      "         -1.1531e-02,  7.5213e-02,  1.5457e-02, -1.0316e-02,  1.9721e-02,\n",
      "          1.6115e-02, -6.7430e-02,  4.6463e-02, -3.2184e-02,  3.8893e-02,\n",
      "          1.3470e-02, -2.8917e-02, -2.0891e-02,  5.5791e-02,  7.8299e-02,\n",
      "         -5.5368e-02,  6.1461e-03,  2.3907e-02,  3.4543e-02, -1.3397e-01,\n",
      "          7.0269e-02, -1.9974e-02, -4.2771e-02,  1.2540e-04, -1.6462e-02,\n",
      "         -2.3798e-02,  3.9062e-04,  3.1662e-02, -3.0879e-03,  7.4438e-03,\n",
      "          2.1378e-02,  1.6758e-02,  1.7697e-02, -5.6043e-02,  3.3667e-02,\n",
      "         -2.7991e-02,  2.5762e-02, -6.2041e-02,  3.3321e-02, -1.3579e-02,\n",
      "         -4.9004e-02, -7.4670e-02,  8.7647e-03, -1.5555e-02, -6.3340e-02,\n",
      "         -2.3084e-02,  7.1130e-05, -1.6550e-02,  5.2097e-03, -1.9965e-03,\n",
      "         -8.3391e-02,  7.2810e-02, -3.0811e-02, -1.0146e-01,  8.2022e-02,\n",
      "          5.3372e-03,  5.4769e-02,  6.5650e-02, -5.3161e-03,  1.1763e-01,\n",
      "          3.6739e-02, -2.0625e-02, -1.8710e-02,  4.6771e-02,  5.2947e-02,\n",
      "         -1.9018e-02,  2.3257e-02, -4.3923e-03,  4.1350e-02,  3.0565e-02,\n",
      "          1.1916e-03, -2.7447e-02, -2.1392e-02,  4.0890e-02, -5.3978e-02,\n",
      "          3.5217e-02, -2.8922e-02,  1.4953e-04, -1.5055e-02,  2.0692e-02,\n",
      "          1.3719e-02, -2.1330e-02, -2.2359e-02,  3.3240e-03,  5.5600e-02,\n",
      "          3.5601e-02, -1.5810e-02, -2.5865e-02,  9.2341e-04, -3.3608e-02,\n",
      "         -2.1004e-02,  2.6068e-02, -1.3797e-01,  4.4908e-03, -4.7949e-02,\n",
      "          6.9971e-02, -4.0762e-02,  6.5589e-03,  1.0158e-01, -1.6900e-02,\n",
      "         -3.8110e-02, -2.6347e-02, -2.9234e-02, -9.7142e-02,  2.3639e-02,\n",
      "         -1.1086e-01, -1.1428e-01, -4.5715e-02,  6.6883e-02, -2.4158e-02,\n",
      "         -5.3285e-02, -2.0520e-02, -8.8668e-02, -1.4827e-02,  3.2409e-02,\n",
      "          5.2342e-03,  2.5434e-02,  3.8320e-02,  3.3415e-03,  5.2801e-02,\n",
      "         -4.1929e-02, -1.2553e-02,  2.8042e-02, -9.0118e-03,  3.7437e-03,\n",
      "         -8.0169e-02,  4.3514e-02,  2.4417e-02,  9.9221e-03, -2.6776e-03,\n",
      "         -1.6400e-02, -9.5870e-03,  4.7455e-02, -3.5728e-02,  6.1941e-03,\n",
      "          8.0722e-02,  5.5618e-03,  1.2783e-02,  7.2492e-02,  2.7334e-02,\n",
      "         -9.1066e-03,  2.3163e-03, -8.1780e-03,  3.9508e-02, -2.7851e-02,\n",
      "         -9.4620e-02,  1.1849e-02,  5.9502e-02,  8.9452e-03,  5.9538e-02,\n",
      "         -1.3567e-02,  3.6960e-02,  5.5056e-02,  8.7000e-02,  5.4479e-02,\n",
      "          4.1732e-02,  2.2367e-02, -1.4369e-02,  1.4618e-02, -5.6922e-02,\n",
      "          7.1464e-02,  1.5445e-02, -3.7733e-02, -4.1933e-02, -3.8170e-02,\n",
      "         -2.4706e-02, -3.7380e-02, -4.3852e-02,  9.5851e-02, -6.6681e-02,\n",
      "         -1.1127e-01, -8.1336e-03, -5.2528e-03,  1.3993e-02,  4.6468e-02,\n",
      "         -2.0613e-02,  6.8918e-02,  7.6750e-02, -1.3836e-05,  6.7182e-03,\n",
      "          7.4994e-02,  1.0726e-02,  3.4501e-02, -2.7077e-02, -1.9601e-02,\n",
      "         -4.8530e-02,  5.5368e-02, -2.1141e-02, -2.5278e-02,  2.1779e-02,\n",
      "          1.7390e-02, -3.6934e-02, -2.5869e-02,  6.9119e-03, -6.2417e-02,\n",
      "         -4.3228e-02,  3.9593e-02,  8.2964e-02, -8.1915e-02,  6.9852e-02,\n",
      "          2.8318e-02,  7.0597e-02, -1.8462e-02, -2.2776e-02, -2.2052e-02,\n",
      "          2.1972e-02, -3.5867e-02, -6.4841e-02,  3.2181e-02,  7.5355e-03,\n",
      "         -1.5583e-02,  5.2567e-02,  9.5430e-03,  9.8377e-02, -1.2222e-02,\n",
      "         -4.1614e-02,  3.9456e-03,  3.5369e-02, -8.1586e-03, -1.7959e-02,\n",
      "          2.6830e-02,  2.0968e-02,  3.5991e-02,  1.2432e-02,  2.9798e-02,\n",
      "          1.9749e-02, -5.3046e-02, -1.4634e-02, -6.4537e-02,  3.3523e-02,\n",
      "         -3.5268e-04,  1.5362e-02,  6.5954e-02,  7.5617e-03,  5.1177e-02,\n",
      "         -7.5070e-03,  2.2298e-02, -1.9951e-02, -2.9321e-02, -5.9214e-03,\n",
      "         -4.6436e-02,  1.2698e-03,  1.1155e-01,  4.2560e-02,  1.4657e-01,\n",
      "         -2.9957e-03,  6.6606e-02,  8.7963e-02, -6.0571e-02,  5.1599e-02,\n",
      "          2.6546e-02,  6.0761e-02,  2.4218e-02,  1.9283e-02,  3.2994e-02,\n",
      "         -2.0698e-02, -1.6826e-02, -3.4828e-02,  2.8772e-05, -2.7851e-02,\n",
      "         -3.6074e-02,  4.8052e-02,  2.2607e-02,  2.8121e-05,  3.9358e-03,\n",
      "         -3.3263e-02, -5.0797e-02,  7.5031e-04, -5.7634e-03,  9.0743e-03,\n",
      "          2.6499e-02,  1.3782e-02,  3.9710e-03, -7.9069e-02, -5.4455e-02,\n",
      "          2.0111e-02, -3.8324e-02,  4.5244e-02, -8.6844e-02, -1.4839e-02,\n",
      "          3.6288e-02,  3.7824e-02,  2.3317e-02,  1.5209e-02, -5.4459e-02,\n",
      "          5.9748e-02, -1.6778e-03, -2.5563e-02,  1.9924e-02,  6.0869e-02,\n",
      "          4.8780e-03, -4.9925e-02, -4.0464e-02, -1.0694e-02,  4.2899e-03,\n",
      "          3.1753e-02, -6.3769e-02,  2.6517e-02, -4.9045e-02, -4.4882e-02,\n",
      "         -7.4203e-03, -7.2089e-04,  1.0595e-01,  5.5946e-03,  9.6075e-03,\n",
      "         -1.2884e-01,  2.8928e-02,  3.0265e-02, -2.0779e-02, -2.6032e-02,\n",
      "         -4.4433e-02,  5.5725e-03, -9.4517e-02,  1.2204e-02,  9.2336e-04,\n",
      "          3.7842e-02, -2.0317e-02,  8.6542e-02,  3.9099e-02, -5.1201e-02,\n",
      "          1.3025e-02,  1.8336e-02,  3.1578e-02,  8.0111e-02, -1.4316e-02,\n",
      "          3.4256e-02,  7.2961e-02, -1.1624e-01,  6.0501e-03, -5.1474e-03,\n",
      "         -6.2065e-03,  6.1667e-02, -2.7768e-03,  5.9096e-02, -1.2868e-02,\n",
      "         -1.7017e-02, -1.0452e-03, -3.8301e-02, -1.6453e-02,  4.6874e-03,\n",
      "         -2.9222e-02, -8.4825e-03, -8.0970e-03,  2.6445e-02, -1.9098e-02,\n",
      "          6.1211e-03, -3.7448e-02,  5.0932e-02,  8.5505e-02, -2.9770e-02,\n",
      "          5.1436e-02, -1.2229e-01, -2.0121e-02,  7.1599e-03,  2.8758e-02,\n",
      "          1.4596e-02,  4.9982e-02, -2.3158e-02, -1.8139e-02,  2.2706e-02,\n",
      "         -1.5587e-02, -7.3934e-02, -6.8916e-02,  3.7032e-02, -5.5521e-02,\n",
      "          9.0887e-03, -6.7006e-03,  4.7372e-02, -6.4798e-03,  1.3685e-02,\n",
      "          4.3693e-02,  4.3916e-02,  1.3010e-02,  3.6250e-02,  2.7846e-02,\n",
      "         -6.2265e-02,  9.4752e-03, -4.7862e-02,  2.8734e-02,  3.4005e-02,\n",
      "          4.6045e-02, -2.9380e-02,  7.1292e-02, -3.9102e-02,  1.9881e-02,\n",
      "          9.3860e-03, -5.7136e-02, -2.5146e-03,  3.3364e-03, -4.1905e-05,\n",
      "         -5.7778e-02,  7.7815e-02,  3.2234e-02,  3.0847e-03,  1.1210e-01,\n",
      "         -2.9487e-02, -3.0207e-03,  8.6729e-03,  2.4024e-02, -7.8736e-03,\n",
      "          3.1299e-03, -2.8514e-02]], device='cuda:0')]\n",
      "batch type:  <class 'list'>\n",
      "key: fbank\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 1024, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 200/200 [00:17<00:00, 11.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.00018654, 0.00015933, 0.00016566, ..., 0.00017977,\n",
       "         0.00019992, 0.00014191]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2audio(\n",
    "    file_name=\"test2\",\n",
    "    images=video_dataset[2][1].to('cuda:0'),\n",
    "    duration=10,\n",
    "    guidance_scale=2.5,\n",
    "    random_seed=42,\n",
    "    n_candidates=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchaudio\n",
    "# from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "# # Load processor and model\n",
    "# processor = AutoProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "# model = AutoModel.from_pretrained(\"laion/clap-htsat-unfused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction.vgg_sound import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:17 videos found in /home/ubuntu/project/subdata/video\n",
      "INFO:root:17 videos found in /home/ubuntu/project/subdata/train_subset.csv\n",
      "INFO:root:48 videos missing in /home/ubuntu/project/subdata/video\n"
     ]
    }
   ],
   "source": [
    "vgg_dataset = VGGSound(root=\"/home/ubuntu/project/subdata/video\",\n",
    "                           csv_path=\"/home/ubuntu/project/subdata/train_subset.csv\")\n",
    "\n",
    "data = vgg_dataset[0]\n",
    "\n",
    "# for data in vgg_dataset:\n",
    "#     # print(data['id'])\n",
    "#     # print(data['audio'].shape)\n",
    "#     # print(data['video'].shape)\n",
    "#     # print(data['video'].shape)\n",
    "#     # if data['id'] == '1msyXyqRvpY_000000.mp4':\n",
    "#     #     print(data['audio'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3843, 0.2980, 0.2706],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4314, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4118, 0.3647, 0.3686],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.6667, 0.6863, 0.8353],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.6902, 0.7020, 0.8510],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7020, 0.7216, 0.8549],\n",
       "         ...,\n",
       "         [0.1765, 0.1765, 0.1725,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.1882, 0.1843, 0.1608,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.1882, 0.1882, 0.1686,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.4902, 0.5059, 0.7137],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5137, 0.5137, 0.7373],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5294, 0.5255, 0.7569],\n",
       "         ...,\n",
       "         [0.0353, 0.0353, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0431, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0471, 0.0275,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4392, 0.5216, 0.8039],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4588, 0.5373, 0.8275],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4706, 0.5569, 0.8588],\n",
       "         ...,\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0235, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0275, 0.0118,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8275],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7647, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7333, 0.7843, 0.8078],\n",
       "         ...,\n",
       "         [0.5961, 0.5961, 0.5922,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.5529, 0.5529, 0.5529,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.5255, 0.5255, 0.5216,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5451, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5725, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5216, 0.6039, 0.7922],\n",
       "         ...,\n",
       "         [0.2745, 0.2745, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2471, 0.2471, 0.2471,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6039, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6392, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6824, 0.8980],\n",
       "         ...,\n",
       "         [0.2392, 0.2392, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1922, 0.1922, 0.1961,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8314],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7686, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7373, 0.7882, 0.8039],\n",
       "         ...,\n",
       "         [0.4078, 0.4039, 0.4039,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.3294, 0.3216, 0.3216,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.2941, 0.3020, 0.2745,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5490, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5765, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5176, 0.6118, 0.7922],\n",
       "         ...,\n",
       "         [0.1294, 0.1216, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0863, 0.0745, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0549, 0.0627, 0.0392,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6078, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6431, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6863, 0.8980],\n",
       "         ...,\n",
       "         [0.0941, 0.0941, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0431, 0.0431, 0.0706,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0118, 0.0275, 0.0275,  ..., 0.0000, 0.0000, 0.0000]]]], )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clip_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# # Load audio file\n",
    "# audio_path = \"input_audio.wav\"\n",
    "# waveform, sr = torchaudio.load(audio_path)\n",
    "waveform = data['audio']\n",
    "\n",
    "# Resample to 48kHz (required by CLAP)\n",
    "# if sr != 48000:\n",
    "# resampler = torchaudio.transforms.Resample(16000, 48000)\n",
    "# waveform = resampler(waveform)\n",
    "\n",
    "# Convert to mono\n",
    "# if waveform.shape[0] > 1:\n",
    "#     waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Prepare inputs for the model\n",
    "inputs = processor(audios=waveform, sampling_rate=48000, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Extract audio embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model.get_audio_features(**inputs)  # shape: [batch, feature_dim]\n",
    "\n",
    "audio_embed = outputs  # shape: [1, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (x * \u001b[32m32767.\u001b[39m).astype(np.int16)\n\u001b[32m     10\u001b[39m model = laion_clap.CLAP_Module(enable_fusion=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# download the default pretrained checkpoint.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/laion_clap/hook.py:114\u001b[39m, in \u001b[36mCLAP_Module.load_ckpt\u001b[39m\u001b[34m(self, ckpt, model_id, verbose)\u001b[39m\n\u001b[32m    112\u001b[39m         logging.info(\u001b[33m'\u001b[39m\u001b[33mDownload completed!\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    113\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mLoad Checkpoint...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m ckpt = \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.model.load_state_dict(ckpt)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/laion_clap/clap_module/factory.py:54\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_path, map_location, skip_params)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_state_dict\u001b[39m(checkpoint_path: \u001b[38;5;28mstr\u001b[39m, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m, skip_params=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m checkpoint:\n\u001b[32m     56\u001b[39m         state_dict = checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/serialization.py:1470\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1462\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1463\u001b[39m                     opened_zipfile,\n\u001b[32m   1464\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1467\u001b[39m                     **pickle_load_args,\n\u001b[32m   1468\u001b[39m                 )\n\u001b[32m   1469\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1471\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1472\u001b[39m             opened_zipfile,\n\u001b[32m   1473\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1476\u001b[39m             **pickle_load_args,\n\u001b[32m   1477\u001b[39m         )\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "# # quantization\n",
    "# def int16_to_float32(x):\n",
    "#     return (x / 32767.0).astype(np.float32)\n",
    "\n",
    "\n",
    "# def float32_to_int16(x):\n",
    "#     x = np.clip(x, a_min=-1., a_max=1.)\n",
    "#     return (x * 32767.).astype(np.int16)\n",
    "\n",
    "# model = laion_clap.CLAP_Module(enable_fusion=False)\n",
    "# model.load_ckpt() # download the default pretrained checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3843, 0.2980, 0.2706],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4314, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4118, 0.3647, 0.3686],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.6667, 0.6863, 0.8353],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.6902, 0.7020, 0.8510],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7020, 0.7216, 0.8549],\n",
       "         ...,\n",
       "         [0.1765, 0.1765, 0.1725,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.1882, 0.1843, 0.1608,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.1882, 0.1882, 0.1686,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.4902, 0.5059, 0.7137],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5137, 0.5137, 0.7373],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5294, 0.5255, 0.7569],\n",
       "         ...,\n",
       "         [0.0353, 0.0353, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0431, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0471, 0.0275,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4392, 0.5216, 0.8039],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4588, 0.5373, 0.8275],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4706, 0.5569, 0.8588],\n",
       "         ...,\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0235, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0275, 0.0118,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8275],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7647, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7333, 0.7843, 0.8078],\n",
       "         ...,\n",
       "         [0.5961, 0.5961, 0.5922,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.5529, 0.5529, 0.5529,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.5255, 0.5255, 0.5216,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5451, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5725, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5216, 0.6039, 0.7922],\n",
       "         ...,\n",
       "         [0.2745, 0.2745, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2471, 0.2471, 0.2471,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6039, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6392, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6824, 0.8980],\n",
       "         ...,\n",
       "         [0.2392, 0.2392, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1922, 0.1922, 0.1961,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8314],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7686, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7373, 0.7882, 0.8039],\n",
       "         ...,\n",
       "         [0.4078, 0.4039, 0.4039,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.3294, 0.3216, 0.3216,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.2941, 0.3020, 0.2745,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5490, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5765, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5176, 0.6118, 0.7922],\n",
       "         ...,\n",
       "         [0.1294, 0.1216, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0863, 0.0745, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0549, 0.0627, 0.0392,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6078, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6431, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6863, 0.8980],\n",
       "         ...,\n",
       "         [0.0941, 0.0941, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0431, 0.0431, 0.0706,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0118, 0.0275, 0.0275,  ..., 0.0000, 0.0000, 0.0000]]]], )"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clip_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data['clip_video'][0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3843, 0.2980, 0.2706],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4314, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4118, 0.3647, 0.3686],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137]]],\n",
       "\n",
       "\n",
       "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
       "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980]],\n",
       "\n",
       "        [[0.1451, 0.1451, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745]],\n",
       "\n",
       "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
       "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.6667, 0.6863, 0.8353],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.6902, 0.7020, 0.8510],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7020, 0.7216, 0.8549],\n",
       "         ...,\n",
       "         [0.1765, 0.1765, 0.1725,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.1882, 0.1843, 0.1608,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.1882, 0.1882, 0.1686,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.4902, 0.5059, 0.7137],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5137, 0.5137, 0.7373],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5294, 0.5255, 0.7569],\n",
       "         ...,\n",
       "         [0.0353, 0.0353, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0431, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0471, 0.0471, 0.0275,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4392, 0.5216, 0.8039],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4588, 0.5373, 0.8275],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4706, 0.5569, 0.8588],\n",
       "         ...,\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0235, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0275, 0.0118,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8275],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7647, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7333, 0.7843, 0.8078],\n",
       "         ...,\n",
       "         [0.5961, 0.5961, 0.5922,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.5529, 0.5529, 0.5529,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.5255, 0.5255, 0.5216,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5451, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5725, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5216, 0.6039, 0.7922],\n",
       "         ...,\n",
       "         [0.2745, 0.2745, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2471, 0.2471, 0.2471,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6039, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6392, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6824, 0.8980],\n",
       "         ...,\n",
       "         [0.2392, 0.2392, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1922, 0.1922, 0.1961,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8314],\n",
       "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7686, 0.8235],\n",
       "         [0.6902, 0.5882, 0.5529,  ..., 0.7373, 0.7882, 0.8039],\n",
       "         ...,\n",
       "         [0.4078, 0.4039, 0.4039,  ..., 0.0431, 0.0314, 0.0431],\n",
       "         [0.3294, 0.3216, 0.3216,  ..., 0.0510, 0.0353, 0.0431],\n",
       "         [0.2941, 0.3020, 0.2745,  ..., 0.0510, 0.0353, 0.0431]],\n",
       "\n",
       "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5490, 0.7843],\n",
       "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5765, 0.7882],\n",
       "         [0.7529, 0.6196, 0.5843,  ..., 0.5176, 0.6118, 0.7922],\n",
       "         ...,\n",
       "         [0.1294, 0.1216, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0863, 0.0745, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0549, 0.0627, 0.0392,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6078, 0.8706],\n",
       "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6431, 0.8902],\n",
       "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6863, 0.8980],\n",
       "         ...,\n",
       "         [0.0941, 0.0941, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0431, 0.0431, 0.0706,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0118, 0.0275, 0.0275,  ..., 0.0000, 0.0000, 0.0000]]]], )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clip_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly get audio embeddings from audio files\n",
    "audio_file = [\n",
    "    '/home/data/test_clap_short.wav',\n",
    "    '/home/data/test_clap_long.wav'\n",
    "]\n",
    "audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=False)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Get audio embeddings from audio data\n",
    "audio_data, _ = librosa.load('/home/data/test_clap_short.wav', sr=48000) # sample rate should be 48000\n",
    "audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
    "audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=False)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Directly get audio embeddings from audio files, but return torch tensor\n",
    "audio_file = [\n",
    "    '/home/data/test_clap_short.wav',\n",
    "    '/home/data/test_clap_long.wav'\n",
    "]\n",
    "audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Get audio embeddings from audio data\n",
    "audio_data, _ = librosa.load('/home/data/test_clap_short.wav', sr=48000) # sample rate should be 48000\n",
    "audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
    "audio_data = torch.from_numpy(int16_to_float32(float32_to_int16(audio_data))).float() # quantize before send it in to the model\n",
    "audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=True)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Get text embedings from texts:\n",
    "text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"] \n",
    "text_embed = model.get_text_embedding(text_data)\n",
    "print(text_embed)\n",
    "print(text_embed.shape)\n",
    "\n",
    "# Get text embedings from texts, but return torch tensor:\n",
    "text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"] \n",
    "text_embed = model.get_text_embedding(text_data, use_tensor=True)\n",
    "print(text_embed)\n",
    "print(text_embed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioldm import image_to_audio, build_model\n",
    "MODEL_NAME = \"audioldm-s-full-v2\"\n",
    "audioldm=build_model(model_name=MODEL_NAME)\n",
    "\n",
    "def image2audio(file_name, images, duration=10, guidance_scale=2.5, random_seed=42, n_candidates=3):\n",
    "    waveform = image_to_audio(\n",
    "        latent_diffusion=audioldm,\n",
    "        images=images,\n",
    "        seed=random_seed,\n",
    "        duration=duration,\n",
    "        guidance_scale=guidance_scale,\n",
    "        n_candidate_gen_per_text=int(n_candidates),\n",
    "    )  # [bs, 1, samples]\n",
    "\n",
    "    for i, wave in enumerate(waveform):\n",
    "        filename = f\"../output/{file_name}.wav\"\n",
    "        sf.write(filename, wave[0], 16000, 'PCM_16') \n",
    "\n",
    "    return waveform\n",
    "\n",
    "image2audio(\n",
    "    file_name=\"test\",\n",
    "    images=data['clip_video'],\n",
    "    duration=10,\n",
    "    guidance_scale=2.5,\n",
    "    random_seed=42,\n",
    "    n_candidates=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load AudioLDM: %s audioldm-s-full-v2\n",
      "DiffusionWrapper has 185.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loading HTSAT-tiny model config.\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"audioldm-s-full-v2\"\n",
    "audioldm=build_model(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2audio(file_name, images, duration=10, guidance_scale=2.5, random_seed=42, n_candidates=3):\n",
    "    waveform = image_to_audio(\n",
    "        latent_diffusion=audioldm,\n",
    "        images=images,\n",
    "        seed=random_seed,\n",
    "        duration=duration,\n",
    "        guidance_scale=guidance_scale,\n",
    "        n_candidate_gen_per_text=int(n_candidates),\n",
    "    )  # [bs, 1, samples]\n",
    "\n",
    "    for i, wave in enumerate(waveform):\n",
    "        filename = f\"../output/{file_name}.wav\"\n",
    "        sf.write(filename, wave[0], 16000, 'PCM_16') \n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate audio using image Image([[[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3843, 0.2980, 0.2706],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.1020, 0.1020]],\n",
      "\n",
      "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4314, 0.3569, 0.3255],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0784, 0.0784]],\n",
      "\n",
      "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1686, 0.1686, 0.1765,  ..., 0.4118, 0.3647, 0.3686],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1137, 0.1137]]],\n",
      "\n",
      "\n",
      "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020]],\n",
      "\n",
      "        [[0.1451, 0.1451, 0.1490,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0784, 0.0784]],\n",
      "\n",
      "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1137, 0.1137]]],\n",
      "\n",
      "\n",
      "       [[[0.1294, 0.1294, 0.1333,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3961, 0.3059, 0.2784],\n",
      "         [0.1255, 0.1255, 0.1294,  ..., 0.3922, 0.3020, 0.2745],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.0980, 0.0980]],\n",
      "\n",
      "        [[0.1451, 0.1451, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.4353, 0.3569, 0.3255],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0745, 0.0745]],\n",
      "\n",
      "        [[0.1765, 0.1765, 0.1804,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1725, 0.1725, 0.1765,  ..., 0.4275, 0.3725, 0.3765],\n",
      "         [0.1686, 0.1686, 0.1765,  ..., 0.4196, 0.3686, 0.3725],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.1098, 0.1098]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.6039, 0.4941, 0.5176,  ..., 0.6667, 0.6863, 0.8353],\n",
      "         [0.7098, 0.5961, 0.6235,  ..., 0.6902, 0.7020, 0.8510],\n",
      "         [0.6902, 0.5882, 0.5529,  ..., 0.7020, 0.7216, 0.8549],\n",
      "         ...,\n",
      "         [0.1765, 0.1765, 0.1725,  ..., 0.0431, 0.0314, 0.0431],\n",
      "         [0.1882, 0.1843, 0.1608,  ..., 0.0510, 0.0353, 0.0431],\n",
      "         [0.1882, 0.1882, 0.1686,  ..., 0.0510, 0.0353, 0.0431]],\n",
      "\n",
      "        [[0.6431, 0.5098, 0.5333,  ..., 0.4902, 0.5059, 0.7137],\n",
      "         [0.7529, 0.6118, 0.6353,  ..., 0.5137, 0.5137, 0.7373],\n",
      "         [0.7529, 0.6196, 0.5843,  ..., 0.5294, 0.5255, 0.7569],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0471, 0.0431, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0471, 0.0471, 0.0275,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.6627, 0.5333, 0.5725,  ..., 0.4392, 0.5216, 0.8039],\n",
      "         [0.7725, 0.6353, 0.6784,  ..., 0.4588, 0.5373, 0.8275],\n",
      "         [0.7922, 0.6627, 0.6471,  ..., 0.4706, 0.5569, 0.8588],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0275, 0.0235, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0275, 0.0275, 0.0118,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8275],\n",
      "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7647, 0.8235],\n",
      "         [0.6902, 0.5882, 0.5529,  ..., 0.7333, 0.7843, 0.8078],\n",
      "         ...,\n",
      "         [0.5961, 0.5961, 0.5922,  ..., 0.0431, 0.0314, 0.0431],\n",
      "         [0.5529, 0.5529, 0.5529,  ..., 0.0510, 0.0353, 0.0431],\n",
      "         [0.5255, 0.5255, 0.5216,  ..., 0.0510, 0.0353, 0.0431]],\n",
      "\n",
      "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5451, 0.7843],\n",
      "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5725, 0.7882],\n",
      "         [0.7529, 0.6196, 0.5843,  ..., 0.5216, 0.6039, 0.7922],\n",
      "         ...,\n",
      "         [0.2745, 0.2745, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2471, 0.2471, 0.2471,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6039, 0.8706],\n",
      "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6392, 0.8902],\n",
      "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6824, 0.8980],\n",
      "         ...,\n",
      "         [0.2392, 0.2392, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2196, 0.2196, 0.2196,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1922, 0.1922, 0.1961,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "       [[[0.6039, 0.4941, 0.5176,  ..., 0.7255, 0.7373, 0.8314],\n",
      "         [0.7098, 0.5961, 0.6235,  ..., 0.7294, 0.7686, 0.8235],\n",
      "         [0.6902, 0.5882, 0.5529,  ..., 0.7373, 0.7882, 0.8039],\n",
      "         ...,\n",
      "         [0.4078, 0.4039, 0.4039,  ..., 0.0431, 0.0314, 0.0431],\n",
      "         [0.3294, 0.3216, 0.3216,  ..., 0.0510, 0.0353, 0.0431],\n",
      "         [0.2941, 0.3020, 0.2745,  ..., 0.0510, 0.0353, 0.0431]],\n",
      "\n",
      "        [[0.6431, 0.5098, 0.5333,  ..., 0.5294, 0.5490, 0.7843],\n",
      "         [0.7529, 0.6118, 0.6353,  ..., 0.5294, 0.5765, 0.7882],\n",
      "         [0.7529, 0.6196, 0.5843,  ..., 0.5176, 0.6118, 0.7922],\n",
      "         ...,\n",
      "         [0.1294, 0.1216, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0863, 0.0745, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0627, 0.0392,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.6627, 0.5333, 0.5725,  ..., 0.4902, 0.6078, 0.8706],\n",
      "         [0.7725, 0.6353, 0.6784,  ..., 0.4902, 0.6431, 0.8902],\n",
      "         [0.7922, 0.6627, 0.6471,  ..., 0.4863, 0.6863, 0.8980],\n",
      "         ...,\n",
      "         [0.0941, 0.0941, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0431, 0.0431, 0.0706,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0118, 0.0275, 0.0275,  ..., 0.0000, 0.0000, 0.0000]]]], )\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 1024, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mimage2audio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclip_video\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mimage2audio\u001b[39m\u001b[34m(file_name, images, duration, guidance_scale, random_seed, n_candidates)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimage2audio\u001b[39m(file_name, images, duration=\u001b[32m10\u001b[39m, guidance_scale=\u001b[32m2.5\u001b[39m, random_seed=\u001b[32m42\u001b[39m, n_candidates=\u001b[32m3\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     waveform = \u001b[43mimage_to_audio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatent_diffusion\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudioldm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_candidate_gen_per_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [bs, 1, samples]\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, wave \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(waveform):\n\u001b[32m     12\u001b[39m         filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/v2a-mapper/audioldm/pipeline.py:131\u001b[39m, in \u001b[36mimage_to_audio\u001b[39m\u001b[34m(latent_diffusion, images, original_audio_file_path, seed, ddim_steps, duration, batchsize, guidance_scale, n_candidate_gen_per_text, config)\u001b[39m\n\u001b[32m    128\u001b[39m latent_diffusion = set_cond_image(latent_diffusion)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     waveform = \u001b[43mlatent_diffusion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43munconditional_guidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mddim_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mddim_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_candidate_gen_per_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_candidate_gen_per_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m waveform\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/v2a-mapper/audioldm/ldm.py:652\u001b[39m, in \u001b[36mLatentDiffusion.generate_sample\u001b[39m\u001b[34m(self, batchs, ddim_steps, ddim_eta, x_T, n_candidate_gen_per_text, unconditional_guidance_scale, unconditional_conditioning, name, use_plms, save, **kwargs)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ema_scope(\u001b[33m\"\u001b[39m\u001b[33mGenerate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batchs:\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m         z, c = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirst_stage_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcond_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcond_stage_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_first_stage_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_c_encode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_original_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m         image = \u001b[38;5;28msuper\u001b[39m().get_input(batch, \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# 从batch里面取出image\u001b[39;00m\n\u001b[32m    663\u001b[39m         \u001b[38;5;66;03m# Generate multiple samples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/v2a-mapper/audioldm/ldm.py:197\u001b[39m, in \u001b[36mLatentDiffusion.get_input\u001b[39m\u001b[34m(self, batch, k, return_first_stage_encode, return_first_stage_outputs, force_c_encode, cond_key, return_original_cond, bs)\u001b[39m\n\u001b[32m    195\u001b[39m     clip = calculate_clip(xc)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         c = v2a_mapper_model(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     c = c[:bs]\n",
      "\u001b[31mRuntimeError\u001b[39m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "image2audio(\n",
    "    file_name=\"test\",\n",
    "    images=data['clip_video'],\n",
    "    duration=10,\n",
    "    guidance_scale=2.5,\n",
    "    random_seed=42,\n",
    "    n_candidates=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "    )\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quant_conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (vocoder): Generator(\n",
       "    (conv_pre): Conv1d(64, 1024, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(1024, 512, kernel_size=(16,), stride=(5,), padding=(5,))\n",
       "      (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "      (2): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "      (3): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (4): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (6): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (7): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (8): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (9): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (10): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (11): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (12): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (13): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (14): ResBlock(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioldm.first_stage_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loading HTSAT-tiny model config.\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/home/ubuntu/miniconda3/envs/v2a-mapper/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Loading pretrained HTSAT-tiny-roberta weights (/home/ubuntu/project/v2a-mapper/pretrain/clap_htsat_tiny.pt).\n"
     ]
    }
   ],
   "source": [
    "from audioldm.clap.encoders import CLAPAudioEmbeddingClassifierFreev2\n",
    "CLAP = CLAPAudioEmbeddingClassifierFreev2(\n",
    "    key='waveform',\n",
    "    pretrained_path=\"/home/ubuntu/project/v2a-mapper/pretrain/clap_htsat_tiny.pt\",\n",
    "    sampling_rate=16000,\n",
    "    embed_mode=\"audio\",\n",
    "    amodel=\"HTSAT-tiny\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wave_file_save_path': './output',\n",
       " 'id': {'version': 'v1',\n",
       "  'name': 'default',\n",
       "  'root': '/mnt/fast/nobackup/users/hl01486/projects/general_audio_generation/AudioLDM-python/config/default/latent_diffusion.yaml'},\n",
       " 'preprocessing': {'audio': {'sampling_rate': 16000, 'max_wav_value': 32768},\n",
       "  'stft': {'filter_length': 1024, 'hop_length': 160, 'win_length': 1024},\n",
       "  'mel': {'n_mel_channels': 64,\n",
       "   'mel_fmin': 0,\n",
       "   'mel_fmax': 8000,\n",
       "   'freqm': 0,\n",
       "   'timem': 0,\n",
       "   'blur': False,\n",
       "   'mean': -4.63,\n",
       "   'std': 2.74,\n",
       "   'target_length': 1024}},\n",
       " 'model': {'device': 'cuda',\n",
       "  'target': 'audioldm.pipline.LatentDiffusion',\n",
       "  'params': {'base_learning_rate': 5e-06,\n",
       "   'linear_start': 0.0015,\n",
       "   'linear_end': 0.0195,\n",
       "   'num_timesteps_cond': 1,\n",
       "   'log_every_t': 200,\n",
       "   'timesteps': 1000,\n",
       "   'first_stage_key': 'fbank',\n",
       "   'cond_stage_key': 'waveform',\n",
       "   'latent_t_size': 256,\n",
       "   'latent_f_size': 16,\n",
       "   'channels': 8,\n",
       "   'cond_stage_trainable': True,\n",
       "   'conditioning_key': 'film',\n",
       "   'monitor': 'val/loss_simple_ema',\n",
       "   'scale_by_std': True,\n",
       "   'unet_config': {'target': 'audioldm.latent_diffusion.openaimodel.UNetModel',\n",
       "    'params': {'image_size': 64,\n",
       "     'extra_film_condition_dim': 512,\n",
       "     'extra_film_use_concat': True,\n",
       "     'in_channels': 8,\n",
       "     'out_channels': 8,\n",
       "     'model_channels': 128,\n",
       "     'attention_resolutions': [8, 4, 2],\n",
       "     'num_res_blocks': 2,\n",
       "     'channel_mult': [1, 2, 3, 5],\n",
       "     'num_head_channels': 32,\n",
       "     'use_spatial_transformer': True}},\n",
       "   'first_stage_config': {'base_learning_rate': 4.5e-05,\n",
       "    'target': 'audioldm.variational_autoencoder.autoencoder.AutoencoderKL',\n",
       "    'params': {'monitor': 'val/rec_loss',\n",
       "     'image_key': 'fbank',\n",
       "     'subband': 1,\n",
       "     'embed_dim': 8,\n",
       "     'time_shuffle': 1,\n",
       "     'ddconfig': {'double_z': True,\n",
       "      'z_channels': 8,\n",
       "      'resolution': 256,\n",
       "      'downsample_time': False,\n",
       "      'in_channels': 1,\n",
       "      'out_ch': 1,\n",
       "      'ch': 128,\n",
       "      'ch_mult': [1, 2, 4],\n",
       "      'num_res_blocks': 2,\n",
       "      'attn_resolutions': [],\n",
       "      'dropout': 0.0}}},\n",
       "   'cond_stage_config': {'target': 'audioldm.clap.encoders.CLAPAudioEmbeddingClassifierFreev2',\n",
       "    'params': {'key': 'waveform',\n",
       "     'sampling_rate': 16000,\n",
       "     'embed_mode': 'audio',\n",
       "     'unconditional_prob': 0.1}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audioldm.utils import default_audioldm_config\n",
    "config = default_audioldm_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2a-mapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
